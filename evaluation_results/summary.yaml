fasttext:
  m1:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: test training
      train_data_description: sample wikipedia, single txt, one sentence per line,
        lowercased, removed punctuation
      train_data_size: 686M
      train_data_md5_hash: 9683602ee186844125ed90eff1fb2dff
      training_epochs: 10
      training_vector_size: 200
      training_window_size: 5
      training_duration (minutes): 37.4
      model_data_size: 4.0G
    score:
      synonyms: 0.05000000074505806
      homonyms: 0.10000000149011612
      antonyms: -0.03999999910593033
  m2:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: test training
      train_data_description: 10% sample of german wikipedia, single txt, one sentence
        per line, lowercased, removed punctuation
      train_data_size: 685M
      train_data_md5_hash: 9683602ee186844125ed90eff1fb2dff
      training_epochs: 100
      training_vector_size: 200
      training_duration (minutes): 371.9
      model_data_size: 2.4G
    score:
      synonyms: 0.05999999865889549
      homonyms: 0.10000000149011612
      antonyms: -0.05999999865889549
  m3:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 10% AMC model
      train_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
        sampled, lowercased, punctuation removed, cleaned from lines not having enough
        text'
      train_data_size: 5.4G
      train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
      training_epochs: 10
      training_vector_size: 200
      training_window_size: 5
      training_duration (minutes): 317.3
      model_data_size: 3.9G
    score:
      synonyms: 0.12999999523162842
      homonyms: 0.1599999964237213
      antonyms: -0.07000000029802322
  m4:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 10% AMC model
      train_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
        sampled, lowercased, punctuation removed, cleaned from lines not having enough
        text'
      train_data_size: 5.4G
      train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
      training_epochs: 50
      training_vector_size: 200
      training_window_size: 5
      training_duration (minutes): 1585
      model_data_size: 3.9G
    score:
      synonyms: 0.11999999731779099
      homonyms: 0.15000000596046448
      antonyms: -0.09000000357627869
  m5:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 10% AMC model
      train_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
        sampled, lowercased, punctuation removed, cleaned from lines not having enough
        text'
      train_data_size: 5.4G
      train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
      training_epochs: 10
      training_vector_size: 300
      training_window_size: 5
      training_duration (minutes): 393.1
      model_data_size: 5.8G
    score:
      synonyms: 0.14000000059604645
      homonyms: 0.15000000596046448
      antonyms: -0.07999999821186066
  m6:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 100% AMC model
      train_data_description: null
      train_data_size: 54G
      train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
      training_epochs: 10
      training_vector_size: 300
      training_window_size: 5
      training_duration (minutes): 4731
      model_data_size: 18G
    score:
      synonyms: 0.1599999964237213
      homonyms: 0.1599999964237213
      antonyms: -0.07999999821186066
  m7:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 100% AMC model
      train_data_description: null
      train_data_size: 54G
      train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
      training_epochs: 10
      training_vector_size: 200
      training_window_size: 5
      training_duration (minutes): 3380
      model_data_size: 12G
    score:
      synonyms: 0.14000000059604645
      homonyms: 0.15000000596046448
      antonyms: -0.07999999821186066
  m8:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 100% AMC model
      train_data_description: null
      train_data_size: 54G
      train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
      training_epochs: 10
      training_vector_size: 200
      training_window_size: 10
      training_duration (minutes): 4923
      model_data_size: 12G
    score:
      synonyms: 0.11999999731779099
      homonyms: 0.15000000596046448
      antonyms: -0.05999999865889549
  m9:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 100% AMC model
      train_data_description: 'Entire AMC: unique sentences, stripped from non-alphanumeric
        lines, lowercased, punctuation removed, removed sentences with too many non-alphanumeric
        characters.'
      train_data_size: 54G
      train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
      training_epochs: 10
      training_vector_size: 300
      training_window_size: 10
      training_duration (minutes): 6513
      model_data_size: 18G
    score:
      synonyms: 0.12999999523162842
      homonyms: 0.1599999964237213
      antonyms: -0.07999999821186066
word2vec:
  m1:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: word2vec test model
      train_data_description: 10% sample of german wikipedia, single txt, one sentence
        per line, lowercased, removed punctuation
      train_data_size: 685M
      train_data_md5_hash: 9683602ee186844125ed90eff1fb2dff
      training_vector_size: 200
      training_epochs: 10
      window: 5
      min_count: 5
      training_duration (minutes): 43.6
      model_data_size: 19M
    score:
      synonyms: 0.09
      homonyms: 0.05
      antonyms: -0.08
  m2:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: word2vec test model
      train_data_description: 10% sample of german wikipedia, single txt, one sentence
        per line, lowercased, removed punctuation
      train_data_size: 685M
      train_data_md5_hash: 9683602ee186844125ed90eff1fb2dff
      training_vector_size: 200
      training_epochs: 100
      window: 5
      min_count: 5
      training_duration (minutes): 215.8
      model_data_size: 19M
    score:
      synonyms: 0.08
      homonyms: 0.04
      antonyms: -0.07
  m3:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 10% AMC model
      train_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
        sampled, lowercased, punctuation removed, cleaned from lines not having enough
        text'
      train_data_size: 5.4G
      train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
      training_vector_size: 200
      training_epochs: 10
      window: 5
      min_count: 5
      training_duration (minutes): 165.3
      model_data_size: 2.4G
    score:
      synonyms: 0.13
      homonyms: 0.12
      antonyms: -0.09
  m4:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 10% AMC model
      train_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
        sampled, lowercased, punctuation removed, cleaned from lines not having enough
        text'
      train_data_size: 5.4G
      train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
      training_vector_size: 200
      training_epochs: 50
      window: 5
      min_count: 5
      training_duration (minutes): 786.8
      model_data_size: 2.4G
    score:
      synonyms: 0.13
      homonyms: 0.12
      antonyms: -0.1
  m5:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 10% AMC model
      train_data_description: 'AMC data: stripped from non-alphanumeric lines, 10%
        sampled, lowercased, punctuation removed, cleaned from lines not having enough
        text'
      train_data_size: 5.4G
      train_data_md5_hash: 33167f260dbf99fa3ceebc3563302954
      training_vector_size: 300
      training_epochs: 10
      window: 5
      min_count: 5
      training_duration (minutes): 188.4
      model_data_size: 3.6G
    score:
      synonyms: 0.14
      homonyms: 0.12
      antonyms: -0.09
  m6:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 100% AMC model
      train_data_description: null
      train_data_size: 54G
      train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
      training_vector_size: 300
      training_epochs: 10
      window: 5
      min_count: 5
      training_duration (minutes): 4573
      model_data_size: 17G
    score:
      synonyms: 0.14
      homonyms: 0.12
      antonyms: -0.09
  m7:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 100% AMC model
      train_data_description: null
      train_data_size: 54G
      train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
      training_vector_size: 200
      training_epochs: 10
      window: 5
      min_count: 5
      training_duration (minutes): 1915
      model_data_size: 11G
    score:
      synonyms: 0.14
      homonyms: 0.11
      antonyms: -0.09
  m8:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 100% AMC model
      train_data_description: null
      train_data_size: 54G
      train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
      training_vector_size: 300
      training_epochs: 10
      window: 10
      min_count: 5
      training_duration (minutes): 10128
      model_data_size: 17G
    score:
      synonyms: 0.14
      homonyms: 0.13
      antonyms: -0.1
  m9:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 100% AMC model
      train_data_description: 'Entire AMC: unique sentences, stripped from non-alphanumeric
        lines, lowercased, punctuation removed, removed sentences with too many non-alphanumeric
        characters.'
      train_data_size: 54G
      train_data_md5_hash: 7e9b50396f77babeef827beff7e506ef
      training_vector_size: 200
      training_epochs: 10
      window: 10
      min_count: 5
      training_duration (minutes): 1847
      model_data_size: 261M
    score:
      synonyms: 0.14
      homonyms: 0.12
      antonyms: -0.1
glove:
  m1:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: glove test model
      train_data_description: 10% sample of german wikipedia, single txt, one article
        per line, lowercased, removed punctuation
      train_data_size: 679M
      train_data_md5_hash: 09bd7f10c1437cc41e32fdda80ba4a34
      verbose: '2'
      memory: '4'
      vocab_min_count: '5'
      vector_size: '200'
      max_iter: '10'
      window_size: '15'
      binary: '2'
      num_threads: '14'
      x_max: '10'
      training_duration (minutes): 47.45
      model_data_size: 16G
    score:
      synonyms: 0.06
      homonyms: 0.04
      antonyms: -0.1
  m2:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: glove test model
      train_data_description: 10% sample of german wikipedia, single txt, one article
        per line, lowercased, removed punctuation
      train_data_size: 679M
      train_data_md5_hash: 09bd7f10c1437cc41e32fdda80ba4a34
      verbose: '2'
      memory: '4'
      vocab_min_count: '5'
      vector_size: '200'
      max_iter: '100'
      window_size: '15'
      binary: '2'
      num_threads: '14'
      x_max: '10'
      training_duration (minutes): 391.06
      model_data_size: 16G
    score:
      synonyms: 0.07
      homonyms: 0.01
      antonyms: -0.12
  m3:
    eval_gold_data: eval_data_lowercase.yaml
    model_details:
      training_description: 1% AMC model
      train_data_description: 1% of AMC
      train_data_size: 552M
      train_data_md5_hash: 05514cc05c6d61fcb3b20076372e2b8a
      verbose: '2'
      memory: '4.0'
      vocab_min_count: '5'
      vector_size: '200'
      max_iter: '10'
      window_size: '15'
      binary: '2'
      num_threads: '14'
      x_max: '10'
      training_duration (minutes): 24.8
      model_data_size: 9.1G
    score:
      synonyms: 0.06
      homonyms: 0.09
      antonyms: -0.11
